[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Hi, I’m a mathematician and like to work with R. Whenever I have a professional problem I first try to find a solution with R.\nIn these blog posts I’d like to share some of my solutions I developed in R for different problems and in doing this I hope to give you some valuable hints for your work."
  },
  {
    "objectID": "about.html#education-and-experience",
    "href": "about.html#education-and-experience",
    "title": "About",
    "section": "Education and Experience",
    "text": "Education and Experience\nYou can find out more about my professional career on my LinkedIn-page."
  },
  {
    "objectID": "posts/makepipe-and-rmarkdown/index.html",
    "href": "posts/makepipe-and-rmarkdown/index.html",
    "title": "Using rmarkdown with makepipe",
    "section": "",
    "text": "In this blog I will demonstrate how you can use makepipe with Rmd-files, so that the dependencies (i.e. the necessary inputs of the workflow within the Rmd) and targets (i.e. the generated outputs of the workflow within the Rmd) don’t have to be known in advance, but are generated by using the exact same code that is used by the Rmd."
  },
  {
    "objectID": "posts/makepipe-and-rmarkdown/index.html#standard-workflow-in-data-science",
    "href": "posts/makepipe-and-rmarkdown/index.html#standard-workflow-in-data-science",
    "title": "Using rmarkdown with makepipe",
    "section": "Standard workflow in data science",
    "text": "Standard workflow in data science\nData science workflows often consists of serveral scripts or functions that have to be executed in a certain order because they depend on one another. That means you have\n\none or more inputs (often data files which are generated by some batch, downloaded or created manually)\none or several outputs (these are the results of your computations and you write them to disk als CSV, XLSX, Rdata or parquet, just to name a few options)"
  },
  {
    "objectID": "posts/makepipe-and-rmarkdown/index.html#what-does-makepipe-has-to-offer",
    "href": "posts/makepipe-and-rmarkdown/index.html#what-does-makepipe-has-to-offer",
    "title": "Using rmarkdown with makepipe",
    "section": "What does makepipe has to offer",
    "text": "What does makepipe has to offer\n\n\n\n\n\n\nTip\n\n\n\nFor a detailed description of what you can do with makepipe developed by Kinto Behr please go to\nBehr K (2025). makepipe: Pipeline Tools Inspired by ‘GNU Make’. R package version 0.2.2, https://github.com/kinto-b/makepipe, https://kinto-b.github.io/makepipe/.\n\n\nWe will use the function makepipe::make_with_source to start a simple R-script that will read in some data, do a little processing and writing an output to disk. In order to do this the make_wih_source-function will need three attributes\n\nsource i.e. the R-script\ntargets i.e. the output-file\ndependencies i.e. the input-file\n\nSo, our R-script will look like this:\n\nlibrary(data.table)\n\n# read data\ndt = fread(\"./one_input.csv\")\n\n# process data\ndt[, new_col := 1L]\n\n# write data\nfwrite(dt, file = \"./one_output.csv\")\n\nIn addition we have another script with has to run after one_source.R` because it’s input is the output of the first script.\n\nlibrary(data.table)\n\n# read data\ndt = fread(\"./one_output.csv\")\n\n# process data\ndt[, newer_col := 2L]\n\n# write data\nfwrite(dt, file = \"./two_output.csv\")"
  },
  {
    "objectID": "posts/makepipe-and-rmarkdown/index.html#a-simple-example",
    "href": "posts/makepipe-and-rmarkdown/index.html#a-simple-example",
    "title": "Using rmarkdown with makepipe",
    "section": "A simple example",
    "text": "A simple example\nLets build a pipeline with theese two scripts\n\nlibrary(makepipe)\n\n# first script\nmake_with_source(source = \"./one_source.R\",\n                 note = \"first script to run\",\n                 targets = \"./one_output.csv\",\n                 dependencies = \"./one_input.csv\")\n\n# second script\nmake_with_source(source = \"./two_source.R\",\n                 note = \"second script to run\",\n                 targets = \"./two_output.csv\",\n                 dependencies = \"./one_output.csv\")\n\nshow_pipeline(as = \"visnetwork\")\n\n\n\n\nDemo Pipeline with dependencies\n\n\nAs you can see all the r-scripts are run and the outputs are produced. If you run the pipeline a second time nothing will be done because alle targets are up-to-date.\nLets delete two_output.csv and look at the visualisation of the pipeline\n\n\n\nDemo Pipeline partially invalidated\n\n\nIf we now run the pipeline again\n\np = get_pipeline()\np$build()\n\n✔ Targets are up to date\n✔ Targets are up to date\n\n\nonly the second R-script is run and all targets are up-to-date again\n\n\n\nDemo Pipeline up-to-date again"
  },
  {
    "objectID": "posts/makepipe-and-rmarkdown/index.html#problem-definition",
    "href": "posts/makepipe-and-rmarkdown/index.html#problem-definition",
    "title": "Using rmarkdown with makepipe",
    "section": "Problem definition",
    "text": "Problem definition\nMost Rmarkdown-files (especially parametrisized Rmd-files) are in itself a kind of mini-pipeline, that is:\n\nYou have an input e.g.\n\na file-path for the input files or\na string by which the input file-paths are constructed;\n\nYou have several steps in your Rmd, e.g.\n\nread input data\nprocess data\ncalculate results\nwrite results to disk\n\n\nWith this in mind our Rmd-File could look like that:\n\n\n---\ntitle: \"RmdScript1\"\nparams:\n  input: \"./input.csv\" \n  output: \"./output.Rdata\"\nauthor: \"Thomas Brand\"\ndate: \"`r Sys.Date()`\"\noutput: html_document\n---\n\n```{r setup, include=FALSE}\nknitr::opts_chunk$set(echo = TRUE)\nlibrary(rlang)\nlibrary(data.table)\n```\n\n# setup inputs and outputs\n\n```{r get-inputs}\ninputs = list()\ninputs = append(inputs,\n                params$input %||% \"./default_input.csv\")\n```\n\n```{r get-outputs}\n\noutputs = list()\noutputs = append(outputs,\n                 params$output %||% \"./default_output.Rdata\")\n\n```\n\n# do some stuff\n\n## read data\n\n```{r read-data}\n\ndt = fread(inputs[[1]])\n```\n\n## manipulate data\n\n```{r manipulate-data}\n\ndt[, colDate := Sys.Date()]\n\n```\n\n# write output\n\n```{r write-output}\n\nsave(dt, file = outputs[[1]])\n```\n\n\nIn order to use make_with_source or to be precise make_with_recipe (as Rmd is not an r-script) you could declare the params$input and params$output as your dependencies and targets that you pass on to the params attribute in the rmarkdown::render function, i.e\n\nrmarkdown::render(input = \"./RmdScript.Rmd\",\n                  output_file = \"./RmdScript_report.html\",\n                  params = list(input = \"input.csv\",\n                                output = \"output.Rdata\"))\n\nThus we would have something like this\n\ninfile = \"one_input.csv\"\noutfile = \"output.Rdata\"\n\nmake_with_recipe(\n  label = \"Render Rmd\",\n  note = \"the code to render the Rmd\",\n  recipe = {\n    rmarkdown::render(input = \"./RmdScript.Rmd\",\n                      output_file = \"./RmdScript_report.html\",\n                      params = list(input = infile,\n                                    output = outfile))\n  },\n  dependencies = infile,\n  targets = outfile,\n)\n\n\n\n\n\n\n\nNote\n\n\n\nPlease be aware that our target is not the rendered html-file of the Rmd, but an Rdata, that is written to disk by the Rmd. The html-file is just used as a protocol-file.\n\n\nIt would work, but is in my opinion cumbersome and, bare in mind, you would extract part of the logic of your mini-pipeline out of the Rmd-File.\nAnd sometimes you would like to construct the filenames of the input- and output-files within your Rmd and just give a basename in the params, e.g.\n\n\n---\ntitle: \"RmdScript1\"\nparams:\n  basename: NULL\nauthor: \"Thomas Brand\"\ndate: \"`r Sys.Date()`\"\noutput: html_document\n---\n\n```{r setup, include=FALSE}\nknitr::opts_chunk$set(echo = TRUE)\nlibrary(rlang)\nlibrary(data.table)\n\nbasename = params$basename %||% \"myfile\"\n```\n\n# setup inputs and outputs\n\n```{r get-inputs}\ninputs = list()\ninputs = append(inputs,\n                paste0(\"./\",basename,\".csv\"))\n```\n\n```{r get-outputs}\n\noutputs = list()\noutputs = append(outputs,\n                paste0(\"./\",basename,\".Rdata\"))\n\n```\n\n# do some stuff\n\n## read data\n\n```{r read-data}\n\ndt = fread(inputs[[1]])\n```\n\n## manipulate data\n\n```{r manipulate-data}\n\ndt[, colDate := Sys.Date()]\n\n```\n\n# write output\n\n```{r write-output}\n\nsave(dt, file = outputs[[1]])\n```"
  },
  {
    "objectID": "posts/makepipe-and-rmarkdown/index.html#solution",
    "href": "posts/makepipe-and-rmarkdown/index.html#solution",
    "title": "Using rmarkdown with makepipe",
    "section": "Solution",
    "text": "Solution\nLet’s think of the chunks of an Rmd-File as Code-snippets, that we can evaluate and that produce certain values/variables. Ideally in the Rmd there is a chunk that will define all the input-files that are used in the Rmd and put them in a list called inputs . These will be our dependencies. The same goes for our outputs (targets) that are in a list called outputs.\nWe want to extract from the Rmd\n\nthe YAML-Header for the params ,\nthe setup- chunk to get all the necessary packages that are used,\nthe get-inputs - chunk to get the code to know the input-files and\nthe get-outputs - chunk to get the code to know the output-files.\n\nIn order to do this we’ll have to build the Rmd with these chunk-names and make sure that they produce the afore mentioned lists.\nAfter that we can execute the chunks in the correct order in a separate environment with the params - list of the YAML-header and extract the necessary variables.\n\nPackage parsermd\n\n\n\n\n\n\nTip\n\n\n\nFor a detailed description of what you can do with parsermd developed by Colin Rundel please go to\nRundel C (2024). parsermd: Formal Parser and Related Tools for R Markdown Documents. R package version 0.2.0, https://github.com/rundel/parsermd, https://rundel.github.io/parsermd/.\n\n\n\n\n\n\n\n\nNote\n\n\n\nWe are using version 0.1.3 of parsermd, so we can’ use YAML-style chunk-options and will use the “classic” chunk-options-form!\n\n\nWhat we intend to do will be taken care of by the parsermd-package. From this package we will need the functions\n\nparse_rmd to get the list of the chunks of the Rmd\nrmd_select to extract just certain chunks\nrmd_source to run a set of chunks\n\nThe necessary code can look like this\n\nlibrary(parsermd)\n\n# get the chunks of our Rmd\nrmd = parse_rmd(rmd = \"./RmdScript.Rmd\")\n\n# select just the named chunks, that we will use\nrmdIO = rmd_select(rmd, \"setup\", \"get-inputs\", \"get-outputs\")\n\n# set up an environment in which we will execute the chunks\nenvIO = new.env()\n\n# extract the params-list of the YAML an put in into the environment\nenvIO$params = rmd_select(rmd,has_type(\"rmd_yaml_list\"))[[1]]$params\n\n# execute the selected code-chunks in the generated environment\nrmd_source(rmdIO, local = envIO)\n\n# extract the input ans output-files to get the targets and dependencies\ninput = unlist(envIO$inputs)\noutputs = unlist(envIO$outputs)\n\n\n\n\n\n\n\nNote\n\n\n\nSometimes you have some variables in the params of your YAML, that you wouldn’t explicitly set in your render-function because they are default values and just could be changed but wouldn’t be changed most times that you run that Rmd. You can do this with the function list_modify of the purrr-package\n\nlibrary(purrr)\nl1 = list(a = 1,\n          b = \"1\",\n          c = 1:3)\n\nl2 = list(b = \"b\",\n          d = 4:5)\n\ncombined_list = list_modify(l1, !!!l2)\ncombined_list\n\n$a\n[1] 1\n\n$b\n[1] \"b\"\n\n$c\n[1] 1 2 3\n\n$d\n[1] 4 5\n\n\n\n\n\n\nLet’s put it all together\nWith this knowledge let’s construct a pipeline for the Rmd where we give just the basename as params.\n\nlibrary(parsermd)\n\nRmd_scriptname = \"./RmdScript_basename.Rmd\"\n\n# get the chunks of our Rmd\nrmd = parse_rmd(rmd = Rmd_scriptname)\n\n# select just the named chunks, that we will use\nrmdIO = rmd_select(rmd, \"setup\", \"get-inputs\", \"get-outputs\")\n\n# set up an environment in which we will execute the chunks\nenvIO = new.env()\n\n# generate the params that we will use to render the Rmd and put them into the environment\nparams = list(basename = \"one_input\")\nenvIO$params = params\n\n# execute the selected code-chunks in the generated environment\nrmd_source(rmdIO, local = envIO)\n\n# extract the input ans output-files to get the targets and dependencies\ninputs = unlist(envIO$inputs)\noutputs = unlist(envIO$outputs)\n\n# construct the pipeline\nmake_with_recipe(\n  label = \"Render Rmd\",\n  note = \"the code to render the Rmd\",\n  recipe = {\n    rmarkdown::render(input = Rmd_scriptname,\n                      output_file = \"./RmdScript_report.html\",\n                      params = params)\n  },\n  dependencies = inputs,\n  targets = outputs,\n)\n\nHere we have\n\nput the params for rendering the Rmd into an environment\nrun the chunks setup, get-inputs, get-outputs in that environment\nextracted the inputs - and outputs -lists from the environment and\ndeclared them as dependencies and targets of our piece of pipeline.\n\nIt just required to build your Rmds according to a certain template, which in my mind isn’t such a bad idea as it helps your future-self to make sense of the Rmds you have written more easily."
  },
  {
    "objectID": "posts/using-fread-for-reading-csv/index.html",
    "href": "posts/using-fread-for-reading-csv/index.html",
    "title": "using-fread-for-reading-csv",
    "section": "",
    "text": "In this blog I will show you how you can use the fread-function of the data.table-package to read in csv-files which don’t adhere to certain standards for csv-files. For this I recommend using a predefined table of structure-information of the csv to read in, which will be used in a function to read in the csv via fread and then convert the data into the correct types."
  },
  {
    "objectID": "posts/using-fread-for-reading-csv/index.html#developing-a-solution",
    "href": "posts/using-fread-for-reading-csv/index.html#developing-a-solution",
    "title": "using-fread-for-reading-csv",
    "section": "Developing a solution",
    "text": "Developing a solution\nThe fread-function offers some options/attributes to solve this problems:\n\ncol.names\ncolClasses\n\n\n\n\n\n\n\nNote\n\n\n\nFor a detailed explanation of what you can do with the data.table-package please see\nBarrett T, Dowle M, Srinivasan A, Gorecki J, Chirico M, Hocking T, Schwendinger B, Krylov I (2025). data.table: Extension of ‘data.frame’. R package version 1.17.99, https://r-datatable.com.\n\n\nA two step process (reading and post-processing) with these two attributes will give us\n\ndtUgly = fread(\"./ugly.csv\",\n               col.names = c(\"client_number\", \"fromDate\", \"toDate\", \"toPayPerMonth\"),\n               colClasses = c(\"character\",\"character\",\"character\",\"numeric\"))\n\ndtUgly[,':='(fromDate = as.Date(fromDate, format = \"%Y%m%d\"),\n             toDate = as.Date(toDate, format = \"%m%d%Y\"))]\n\ndtUgly\n\n   client_number   fromDate     toDate toPayPerMonth\n          &lt;char&gt;     &lt;Date&gt;     &lt;Date&gt;         &lt;num&gt;\n1:           001 2025-01-01 2025-05-01          1.23\n2:           123 2024-12-24 2025-02-02          2.34\n3:        987654 2025-07-05 2099-12-31          3.45\n\n\nwhich is the correct solution."
  },
  {
    "objectID": "posts/using-fread-for-reading-csv/index.html#using-predefined-data-structures",
    "href": "posts/using-fread-for-reading-csv/index.html#using-predefined-data-structures",
    "title": "using-fread-for-reading-csv",
    "section": "Using predefined data-structures",
    "text": "Using predefined data-structures\nIf you are reading such a csv only once the procedure above works quite well. But if you have several different csv-files it might be tedious to program a separate function for each csv.\nImagine you have a function with the attributes\n\npathToCSV\nstructureOfCSV\n\nThe key to this function is the kind of information that you encode in structureOfCSV. This attribute is a data.table with the following columns:\n\nnames for the column-names\nclasses for die classes of the columns\ndateTypes for the format of the date-columns\nnumericFactor for manipulations to numeric columns\n\nLet’s have a look at the function\n\nreadCSV = function(pathToCSV,\n                   structureOfCSV) {\n  # read csv\n  dt = fread(input = pathToCSV,\n             col.names = structureOfCSV$names,\n             colClasses = structureOfCSV$classes)\n  \n  # convert date-types\n  dateCols = structureOfCSV[!is.na(dateTypes),.(names, dateTypes)]\n  \n  if(nrow(dateCols) &gt; 0) {\n    for (i in 1:nrow(dateCols)) {\n      name = dateCols[i]$names\n      dt[,(name) := as.Date(get(name),format = dateCols[i]$dateTypes)]\n    }\n  }\n  \n  # convert numeric types\n  numericCols = structureOfCSV[!is.na(numericFactor),.(names, numericFactor)]\n  \n  if(nrow(numericCols) &gt; 0) {\n    for (i in 1:nrow(numericCols)) {\n      name = numericCols[i]$names\n      dt[,(name) := get(name) * numericCols[i]$numericFactor]\n    }\n  }\n  \n  return(dt)\n}\n\nThe corresponding structure for our file “ugly.csv” would look like this\n\nstructureOfCSV = data.table(\n  names = c(\"client_number\", \"fromDate\", \"toDate\", \"toPayPerMonth\"),\n  classes = c(\"character\",\"character\",\"character\",\"numeric\"),\n  dateTypes = c(NA_character_,\"%Y%m%d\",\"%m%d%Y\",NA_character_),\n  numericFactor = c(NA_real_,NA_real_,NA_real_,NA_real_)\n)\n\nLet’s see how it can all work together:\n\ntbl = readCSV(\"./ugly.csv\",\n              structureOfCSV)\n\ntbl\n\n   client_number   fromDate     toDate toPayPerMonth\n          &lt;char&gt;     &lt;Date&gt;     &lt;Date&gt;         &lt;num&gt;\n1:           001 2025-01-01 2025-05-01          1.23\n2:           123 2024-12-24 2025-02-02          2.34\n3:        987654 2025-07-05 2099-12-31          3.45\n\n\nand it will do the trick.\n\n\n\n\n\n\nTip\n\n\n\nTo go even further you would have a repository of different structureOfCSV-objects - one for each kind of csv-file you have to read.\nYou cold even build some wrapper-functions around readCSV which use just the predefined structure. Imagine you have the structures structureofCSV1 and structureOfCSV2.\n\nstructureOfCSV1 = data.table(\n  names = c(\"client_number\", \"fromDate\"),\n  classes = c(\"character\",\"character\"),\n  dateTypes = c(NA_character_,\"%Y%m%d\"),\n  numericFactor = c(NA_real_,NA_real_)\n)\n\nstructureOfCSV2 = data.table(\n  names = c(\"client_number\", \"toDate\", \"toPayPerMonth\"),\n  classes = c(\"character\",\"character\",\"numeric\"),\n  dateTypes = c(NA_character_,\"%m%d%Y\",NA_character_),\n  numericFactor = c(NA_real_,NA_real_,NA_real_)\n)\n\nYou would then build the following functions\n\nreadCSV1 = function(pathToCSV) {\n  readCSV(pathToCSV = pathToCSV,\n          structureOfCSV = structureOfCSV1)\n}\n\nreadCSV2 = function(pathToCSV) {\n  readCSV(pathToCSV = pathToCSV,\n          structureOfCSV = structureOfCSV2)\n}\n\n# usage\n#dt1 = readCSV1(\"insert path here\")\n#dt2 = readCSV2(\"insert path here\")\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nWe didn’t use the option of numericFactor as our csv had a decimal point. You would have used this option if the values are in cent instead of dollar/euro.\nYou could also expand the functionality of readCSV further by providing columns in structureOfCSV such as\n\nrounding, to round numbers\nsplit.character, to split a character column into several columns containing different informations\netc."
  },
  {
    "objectID": "posts/using-foverlaps-for-time-slices/index.html",
    "href": "posts/using-foverlaps-for-time-slices/index.html",
    "title": "using foverlaps for time-slices",
    "section": "",
    "text": "In this blog I will show you how to split time-slices in client-data so that each row will be reproduced as many times as there are overlaps with a given set of relevant intervals by also preserving the other relevant information of the rows. We will do this by using the foverlaps-function of the data.table package together with some tweaks. We will cover some special cases, too."
  },
  {
    "objectID": "posts/using-foverlaps-for-time-slices/index.html#explanation-for-date-intervals",
    "href": "posts/using-foverlaps-for-time-slices/index.html#explanation-for-date-intervals",
    "title": "using foverlaps for time-slices",
    "section": "Explanation for date intervals",
    "text": "Explanation for date intervals\nWith this date conventions\n\nthe startDate is the first date that the row is valid and\nthe endDate is the first date that the row isn’t valid any more,\n\nyou can easily calculate the months with the lubridate-package and the interval-function\n\nlibrary(lubridate)\n\n# Calculate the months\ninterval(start = as.Date(\"2025-02-01\"), end = as.Date(\"2025-04-01\")) %/% months(1)\n\n[1] 2\n\n\nIf we had the convention that the endDate would be the last date where the row is still valid the calulations wouldn’t add up.\n\n# Calculate the months\ninterval(start = as.Date(\"2025-02-01\"), end = as.Date(\"2025-03-31\")) %/% months(1)\n\n[1] 1"
  },
  {
    "objectID": "posts/using-foverlaps-for-time-slices/index.html#introduction-of-foverlaps",
    "href": "posts/using-foverlaps-for-time-slices/index.html#introduction-of-foverlaps",
    "title": "using foverlaps for time-slices",
    "section": "Introduction of foverlaps",
    "text": "Introduction of foverlaps\n\n\n\n\n\n\nNote\n\n\n\nFor a detailed explanation of what you can do with the data.table-package please see\nBarrett T, Dowle M, Srinivasan A, Gorecki J, Chirico M, Hocking T, Schwendinger B, Krylov I (2025). data.table: Extension of ‘data.frame’. R package version 1.17.99, https://r-datatable.com.\n\n\nFirst, we will generate a data.table with two columns for the begin and the end of an interval. Each row will cover exactly one month. This can be done with the following code.\n\nintervals = data.table(startDate = seq(as.Date(\"2024-09-01\"), to = as.Date(\"2025-04-01\"), by = \"month\"))\nintervals[,endDate := shift(startDate, type = \"lead\")]\nintervals = na.omit(intervals)\ncols = c(\"startDate\",\"endDate\")\nsetkeyv(intervals, cols)\nintervals\n\n\n\n\n\nstartDate\nendDate\n\n\n\n\n2024-09-01\n2024-10-01\n\n\n2024-10-01\n2024-11-01\n\n\n2024-11-01\n2024-12-01\n\n\n2024-12-01\n2025-01-01\n\n\n2025-01-01\n2025-02-01\n\n\n2025-02-01\n2025-03-01\n\n\n2025-03-01\n2025-04-01\n\n\n\n\n\n\nNext we will start a first try to see what foverlaps will produce. We expect\n\n7 rows for customer A Plan T1 (i.e. for erery row in intervals)\n\n\n\n\nstartDate\nendDate\n\n\n\n\n2024-09-01\n2024-10-01\n\n\n2024-10-01\n2024-11-01\n\n\n2024-11-01\n2024-12-01\n\n\n2024-12-01\n2025-01-01\n\n\n2025-01-01\n2025-02-01\n\n\n2025-02-01\n2025-03-01\n\n\n2025-03-01\n2025-04-01\n\n\n\n4 rows für customer B Plan T1\n\n\n\n\nstartDate\nendDate\n\n\n\n\n2024-11-06\n2024-12-01\n\n\n2024-12-01\n2025-01-01\n\n\n2025-01-01\n2025-02-01\n\n\n2025-02-01\n2025-03-01\n\n\n\n1 row für customer B Plan T2\n\n\n\n\nstartDate\nendDate\n\n\n\n\n2025-03-01\n2025-04-01\n\n\n\n4 rows for customer C Plan T2\n\n\n\n\nstartDate\nendDate\n\n\n\n\n2024-09-01\n2024-10-01\n\n\n2024-10-01\n2024-11-01\n\n\n2024-11-01\n2024-12-01\n\n\n2024-12-01\n2025-01-01\n\n\n\n\nWe get instead\n\nresult = foverlaps(dt, intervals, by.x = cols, by.y = cols)\nresult\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nstartDate\nendDate\nclient\nplan\ni.startDate\ni.endDate\nbasicPrice\ndiscount\ntoPayPerMonth\n\n\n\n\n2024-09-01\n2024-10-01\nA\nT1\n2024-07-06\n9999-12-31\n12.34\n-0.34\n12.00\n\n\n2024-10-01\n2024-11-01\nA\nT1\n2024-07-06\n9999-12-31\n12.34\n-0.34\n12.00\n\n\n2024-11-01\n2024-12-01\nA\nT1\n2024-07-06\n9999-12-31\n12.34\n-0.34\n12.00\n\n\n2024-12-01\n2025-01-01\nA\nT1\n2024-07-06\n9999-12-31\n12.34\n-0.34\n12.00\n\n\n2025-01-01\n2025-02-01\nA\nT1\n2024-07-06\n9999-12-31\n12.34\n-0.34\n12.00\n\n\n2025-02-01\n2025-03-01\nA\nT1\n2024-07-06\n9999-12-31\n12.34\n-0.34\n12.00\n\n\n2025-03-01\n2025-04-01\nA\nT1\n2024-07-06\n9999-12-31\n12.34\n-0.34\n12.00\n\n\n2024-11-01\n2024-12-01\nB\nT1\n2024-11-06\n2025-03-01\n23.45\n-1.45\n22.00\n\n\n2024-12-01\n2025-01-01\nB\nT1\n2024-11-06\n2025-03-01\n23.45\n-1.45\n22.00\n\n\n2025-01-01\n2025-02-01\nB\nT1\n2024-11-06\n2025-03-01\n23.45\n-1.45\n22.00\n\n\n2025-02-01\n2025-03-01\nB\nT1\n2024-11-06\n2025-03-01\n23.45\n-1.45\n22.00\n\n\n2025-03-01\n2025-04-01\nB\nT1\n2024-11-06\n2025-03-01\n23.45\n-1.45\n22.00\n\n\n2025-02-01\n2025-03-01\nB\nT2\n2025-03-01\n9999-12-31\n34.56\n0.00\n34.56\n\n\n2025-03-01\n2025-04-01\nB\nT2\n2025-03-01\n9999-12-31\n34.56\n0.00\n34.56\n\n\n2024-09-01\n2024-10-01\nC\nT2\n2024-08-01\n2025-01-01\n14.79\n-3.79\n11.00\n\n\n2024-10-01\n2024-11-01\nC\nT2\n2024-08-01\n2025-01-01\n14.79\n-3.79\n11.00\n\n\n2024-11-01\n2024-12-01\nC\nT2\n2024-08-01\n2025-01-01\n14.79\n-3.79\n11.00\n\n\n2024-12-01\n2025-01-01\nC\nT2\n2024-08-01\n2025-01-01\n14.79\n-3.79\n11.00\n\n\n2025-01-01\n2025-02-01\nC\nT2\n2024-08-01\n2025-01-01\n14.79\n-3.79\n11.00\n\n\n\n\n\n\nWe can see, that every row of the original table was multiplied into as many rows as had overlaps with the rows of the intervals-table.\nIn the result we have\n\nstartDate and endDate as the corresponding values of the intervals-table and\ni.startDate and i.endDate as the original values of the table\nwe did get\n\nthe 7 rows for customer A Plan T1\n5 rows instead of 4 for customer B Plan T1 an the wrong start date for the fisrt row\n2 rows instead of 1 for customer B Plan T2\n5 rowa instead of 4 for customer C Plan T2\n\n\nLet’s look closer at the rows with the numbers 12, 13, 19\n\nresult[c(12,13,19)]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nstartDate\nendDate\nclient\nplan\ni.startDate\ni.endDate\nbasicPrice\ndiscount\ntoPayPerMonth\n\n\n\n\n2025-03-01\n2025-04-01\nB\nT1\n2024-11-06\n2025-03-01\n23.45\n-1.45\n22.00\n\n\n2025-02-01\n2025-03-01\nB\nT2\n2025-03-01\n9999-12-31\n34.56\n0.00\n34.56\n\n\n2025-01-01\n2025-02-01\nC\nT2\n2024-08-01\n2025-01-01\n14.79\n-3.79\n11.00\n\n\n\n\n\n\nComparing startDate and endDate with i.startDate and i.endDate we can see the foverlaps generated a row for the month, but that the current intervals ended the month before or didn’t even have started.\n\n\n\n\n\n\nImportant\n\n\n\nThe reason for this is, that we have defined our intervals as open on the right.\nBy default the foverlaps-function used an overlap-mode “any” which will produce an overlap of two intervals \\([a,b]\\) and \\([c,d]\\) if \\(c\\le b \\wedge d\\ge a\\) . So all intervals are treated as closed intervals.\nUnfortunately the other available types of overlaps in foverlaps don’t suit our requirements:\n\n“within” - the interval has to lie within the other to overlap\n“start” - the start-dates have to be equal to overlap\n“end” - the end-dates have to be equal to overlap\n“equal” - the intervals have to be identical to overlap\n\nMaybe this will change if the minoverlap-attribute is implemented.\n\n\nOn the other hand we have row 8, which is also wrong\n\nresult[c(8)]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nstartDate\nendDate\nclient\nplan\ni.startDate\ni.endDate\nbasicPrice\ndiscount\ntoPayPerMonth\n\n\n\n\n2024-11-01\n2024-12-01\nB\nT1\n2024-11-06\n2025-03-01\n23.45\n-1.45\n22\n\n\n\n\n\n\nComparing the original values with the new ones we can see, that the row isn’t correct, as \\([2024-11-01,2024-12-01)\\) isn’t completely contained in the original interval \\([2024-11-06,2025-03-01)\\)."
  },
  {
    "objectID": "posts/using-foverlaps-for-time-slices/index.html#transforming-the-intervals---enddate",
    "href": "posts/using-foverlaps-for-time-slices/index.html#transforming-the-intervals---enddate",
    "title": "using foverlaps for time-slices",
    "section": "Transforming the intervals - endDate",
    "text": "Transforming the intervals - endDate\nTherefore we have to change our intervals from open on the right side to closed on the right side. We can do this by subtracting one day from the end. We will create a new column endDatem1 in our dt- and our intervals-tables.\n\ndt[,endDatem1 := endDate - days(1)]\nintervals[,endDatem1 := endDate - days(1)]\ncolsm1 = c(\"startDate\",\"endDatem1\")\nsetkeyv(intervals, colsm1)\nintervals\n\n\n\n\n\nstartDate\nendDate\nendDatem1\n\n\n\n\n2024-09-01\n2024-10-01\n2024-09-30\n\n\n2024-10-01\n2024-11-01\n2024-10-31\n\n\n2024-11-01\n2024-12-01\n2024-11-30\n\n\n2024-12-01\n2025-01-01\n2024-12-31\n\n\n2025-01-01\n2025-02-01\n2025-01-31\n\n\n2025-02-01\n2025-03-01\n2025-02-28\n\n\n2025-03-01\n2025-04-01\n2025-03-31\n\n\n\n\n\n\nLets try foverlaps again with startDate and endDatem1.\n\nresult_m1 = foverlaps(dt, intervals, by.x = colsm1, by.y = colsm1)\ncol_selected = c(\"startDate\",\"endDate\",\"client\",\"plan\",\"i.startDate\",\"i.endDate\",\"basicPrice\",\"discount\",\"toPayPerMonth\")\nresult_m1[,..col_selected]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nstartDate\nendDate\nclient\nplan\ni.startDate\ni.endDate\nbasicPrice\ndiscount\ntoPayPerMonth\n\n\n\n\n2024-09-01\n2024-10-01\nA\nT1\n2024-07-06\n9999-12-31\n12.34\n-0.34\n12.00\n\n\n2024-10-01\n2024-11-01\nA\nT1\n2024-07-06\n9999-12-31\n12.34\n-0.34\n12.00\n\n\n2024-11-01\n2024-12-01\nA\nT1\n2024-07-06\n9999-12-31\n12.34\n-0.34\n12.00\n\n\n2024-12-01\n2025-01-01\nA\nT1\n2024-07-06\n9999-12-31\n12.34\n-0.34\n12.00\n\n\n2025-01-01\n2025-02-01\nA\nT1\n2024-07-06\n9999-12-31\n12.34\n-0.34\n12.00\n\n\n2025-02-01\n2025-03-01\nA\nT1\n2024-07-06\n9999-12-31\n12.34\n-0.34\n12.00\n\n\n2025-03-01\n2025-04-01\nA\nT1\n2024-07-06\n9999-12-31\n12.34\n-0.34\n12.00\n\n\n2024-11-01\n2024-12-01\nB\nT1\n2024-11-06\n2025-03-01\n23.45\n-1.45\n22.00\n\n\n2024-12-01\n2025-01-01\nB\nT1\n2024-11-06\n2025-03-01\n23.45\n-1.45\n22.00\n\n\n2025-01-01\n2025-02-01\nB\nT1\n2024-11-06\n2025-03-01\n23.45\n-1.45\n22.00\n\n\n2025-02-01\n2025-03-01\nB\nT1\n2024-11-06\n2025-03-01\n23.45\n-1.45\n22.00\n\n\n2025-03-01\n2025-04-01\nB\nT2\n2025-03-01\n9999-12-31\n34.56\n0.00\n34.56\n\n\n2024-09-01\n2024-10-01\nC\nT2\n2024-08-01\n2025-01-01\n14.79\n-3.79\n11.00\n\n\n2024-10-01\n2024-11-01\nC\nT2\n2024-08-01\n2025-01-01\n14.79\n-3.79\n11.00\n\n\n2024-11-01\n2024-12-01\nC\nT2\n2024-08-01\n2025-01-01\n14.79\n-3.79\n11.00\n\n\n2024-12-01\n2025-01-01\nC\nT2\n2024-08-01\n2025-01-01\n14.79\n-3.79\n11.00\n\n\n\n\n\n\nFor clarity we have omitted the m1-suffix columns in the output. As we can see the results are correct now. The incorrect rows 12, 13 and 19 have vanished."
  },
  {
    "objectID": "posts/using-foverlaps-for-time-slices/index.html#transforming-the-intervals---startdate",
    "href": "posts/using-foverlaps-for-time-slices/index.html#transforming-the-intervals---startdate",
    "title": "using foverlaps for time-slices",
    "section": "Transforming the intervals - startDate",
    "text": "Transforming the intervals - startDate\nTo correct the incorrect row number 8 we have to replace the startDate in every row where it is smaller than i.startDate with the value in i.startDate\n\nresult_m1[startDate &lt; i.startDate, startDate := i.startDate]\nresult_m1[,..col_selected]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nstartDate\nendDate\nclient\nplan\ni.startDate\ni.endDate\nbasicPrice\ndiscount\ntoPayPerMonth\n\n\n\n\n2024-09-01\n2024-10-01\nA\nT1\n2024-07-06\n9999-12-31\n12.34\n-0.34\n12.00\n\n\n2024-10-01\n2024-11-01\nA\nT1\n2024-07-06\n9999-12-31\n12.34\n-0.34\n12.00\n\n\n2024-11-01\n2024-12-01\nA\nT1\n2024-07-06\n9999-12-31\n12.34\n-0.34\n12.00\n\n\n2024-12-01\n2025-01-01\nA\nT1\n2024-07-06\n9999-12-31\n12.34\n-0.34\n12.00\n\n\n2025-01-01\n2025-02-01\nA\nT1\n2024-07-06\n9999-12-31\n12.34\n-0.34\n12.00\n\n\n2025-02-01\n2025-03-01\nA\nT1\n2024-07-06\n9999-12-31\n12.34\n-0.34\n12.00\n\n\n2025-03-01\n2025-04-01\nA\nT1\n2024-07-06\n9999-12-31\n12.34\n-0.34\n12.00\n\n\n2024-11-06\n2024-12-01\nB\nT1\n2024-11-06\n2025-03-01\n23.45\n-1.45\n22.00\n\n\n2024-12-01\n2025-01-01\nB\nT1\n2024-11-06\n2025-03-01\n23.45\n-1.45\n22.00\n\n\n2025-01-01\n2025-02-01\nB\nT1\n2024-11-06\n2025-03-01\n23.45\n-1.45\n22.00\n\n\n2025-02-01\n2025-03-01\nB\nT1\n2024-11-06\n2025-03-01\n23.45\n-1.45\n22.00\n\n\n2025-03-01\n2025-04-01\nB\nT2\n2025-03-01\n9999-12-31\n34.56\n0.00\n34.56\n\n\n2024-09-01\n2024-10-01\nC\nT2\n2024-08-01\n2025-01-01\n14.79\n-3.79\n11.00\n\n\n2024-10-01\n2024-11-01\nC\nT2\n2024-08-01\n2025-01-01\n14.79\n-3.79\n11.00\n\n\n2024-11-01\n2024-12-01\nC\nT2\n2024-08-01\n2025-01-01\n14.79\n-3.79\n11.00\n\n\n2024-12-01\n2025-01-01\nC\nT2\n2024-08-01\n2025-01-01\n14.79\n-3.79\n11.00\n\n\n\n\n\n\nWe can now use startDate and endDate for further calculations.\n\n\n\n\n\n\nNote\n\n\n\nIt is important, that we tweaked the result in exact this order\n\ntransforming endDate\ntransforming startDate\n\nOtherwise we wouldn’t have gotten the correct result."
  },
  {
    "objectID": "posts/using-foverlaps-for-time-slices/index.html#solutions-for-special-forms-of-intervals",
    "href": "posts/using-foverlaps-for-time-slices/index.html#solutions-for-special-forms-of-intervals",
    "title": "using foverlaps for time-slices",
    "section": "Solutions for special forms of intervals",
    "text": "Solutions for special forms of intervals\nThe solution above works as long as you are dealing with real intervals \\([a,b)\\) where \\(a&lt;b\\) .\nSometimes, however, you can have the situation, that you have records that are only valid “a logical second”, meaning that you documented some changes in your records, but these changes didn’t lead to a real time span. In this case you have intervals where \\(a=b\\).\n\ndt_special = data.table(startDate = as.Date(c(\"2025-01-01\",\"2025-02-01\",\"2025-02-01\")),\n                        endDate = as.Date(c(\"2025-02-01\",\"2025-02-01\",\"9999-12-31\")),\n                        name = c(\"Doe\",\"Smith\",\"Smith\"),\n                        toPayPerMonth = c(1.23,1.23,2.34))\n\ndt_special[,endDatem1 := endDate - days(1)]\ndt_special\n\n\n\n\n\nstartDate\nendDate\nname\ntoPayPerMonth\nendDatem1\n\n\n\n\n2025-01-01\n2025-02-01\nDoe\n1.23\n2025-01-31\n\n\n2025-02-01\n2025-02-01\nSmith\n1.23\n2025-01-31\n\n\n2025-02-01\n9999-12-31\nSmith\n2.34\n9999-12-30\n\n\n\n\n\n\nLets see how foverlaps handles these situations:\n\nresult_sp1 = foverlaps(dt_special, intervals, by.x = colsm1, by.y = colsm1) \n\nError in foverlaps(dt_special, intervals, by.x = colsm1, by.y = colsm1): All entries in column 'startDate' should be &lt;= corresponding entries in column 'endDatem1' in data.table x.\n\n\nAs you can see the foverlaps-function returns an error-message.\n\nOmit these rows if possible\nIn our use-case of this blog the easiest solution would be eliminate these rows from our dataset, as we are only interested in the amount someone has to pay which is time/date multiplied by the sum to pay per month. Lets see how we can do this\n\nresult_sp2 = foverlaps(dt_special[startDate &lt;= endDatem1], intervals, by.x = colsm1, by.y = colsm1)\nresult_sp2[,.(startDate,endDate,name,toPayPerMonth)]\n\n\n\n\n\nstartDate\nendDate\nname\ntoPayPerMonth\n\n\n\n\n2025-01-01\n2025-02-01\nDoe\n1.23\n\n\n2025-02-01\n2025-03-01\nSmith\n2.34\n\n\n2025-03-01\n2025-04-01\nSmith\n2.34\n\n\n\n\n\n\nIt works, but we loose the information, that the name-change didn’t cause a change of the payment per month.\n\n\nManipulate the start columns as well\nIf on the other hand we are interested in conserving the information that the name-change happened without change of payment per month, we will need a different approach\n\ndt_special[startDate == endDate, startDate := startDate - days(1)]\nresult_sp3 = foverlaps(dt_special, intervals, by.x = colsm1, by.y = colsm1)\nresult_sp3[i.startDate == endDatem1, startDate := endDate]\nresult_sp3\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nstartDate\nendDate\nendDatem1\ni.startDate\ni.endDate\nname\ntoPayPerMonth\ni.endDatem1\n\n\n\n\n2025-01-01\n2025-02-01\n2025-01-31\n2025-01-01\n2025-02-01\nDoe\n1.23\n2025-01-31\n\n\n2025-02-01\n2025-02-01\n2025-01-31\n2025-01-31\n2025-02-01\nSmith\n1.23\n2025-01-31\n\n\n2025-02-01\n2025-03-01\n2025-02-28\n2025-02-01\n9999-12-31\nSmith\n2.34\n9999-12-30\n\n\n2025-03-01\n2025-04-01\n2025-03-31\n2025-02-01\n9999-12-31\nSmith\n2.34\n9999-12-30\n\n\n\n\n\n\nWhat we did was:\n\nsubtract 1 day from startDate if it equals endDate\ndo our foverlaps procedure from above\nset startDate to endDate if the original i.startDate (the one we changed) equals our manipulated endDatem1"
  },
  {
    "objectID": "posts/calculating-months-with-fractiions/index.html",
    "href": "posts/calculating-months-with-fractiions/index.html",
    "title": "Calculating months with fractions",
    "section": "",
    "text": "Abstract\nIn this blog I will show you how you can calculate the number of months between two dates with the lubridate-package. This is quite an easy task, but you have to take into account certain special cases in which you might get a result, that is not quite what you would expect. I will also give you an solution of how you can avoid this problem.\n\n\nProblem definition\nIn many cases you have the situation, that you bill a customer on a per month basis, e.g. in a subscription for a service. So any record (i.e. row) has a\n\nstartDate which is the first day, that a row is valid and an\nendDate which is the first day, that a row isn’t valid any more.\n\nWith this in mind you can easily calculate the months between two dates as the difference between the months of your dates if you subtract them.\n\nlibrary(data.table)\nlibrary(lubridate)\n\nstart = as.Date(\"2025-01-01\")\nend = as.Date(\"2025-03-01\")\n\nmonths_between = month(end) - month(start)\nmonths_between\n\n[1] 2\n\n\nIn this case it doesn’t matter how many days the month has, i.e. February with its 28 (29) days count as equally as one month as does March with its 31 days.\nApart for the obvious problems with year-changes in this calculation-approach, we will also have to deal with beginnings or endings within a month. This could be because someone started the subscription not on the first of a month or terminated the service before the end of the month, e.g. by right of premature cancellation or just because the person died.\nIn this cases you can’t bill the customer for the whole month, just for the days he used the service. By definition we will assume that for \\(x\\) days of service we can bill the customer with \\(\\frac{x}{dsom}\\) of the monthly payment, with \\(dsom\\) the number of days of the corresponding month.\nSo, let’s look at several different situations of possible scenarios for calculating the month-with-fractions.\n\ndt = rowwiseDT(start=, end=, expected=, descr=,\n               \"2025-01-01\",\"2025-02-01\", 1.0,       \"1 month\",\n               \"2024-11-01\",\"2025-02-01\", 3.0,       \"3 months\",\n               \"2025-01-01\",\"2025-02-10\", 1 + 9/28,  \"1 month and 9 days of February\",\n               \"2025-01-15\",\"2025-02-01\", 17/31,     \"17 days\",\n               \"2025-02-01\",\"2025-03-10\", 1 + 9/31,  \"1 month an 9 days of March\",\n               \"2025-01-15\",\"2025-03-01\", 1 + 14/28, \"1 month and 14 days of February\",\n               \"2025-01-15\",\"2025-03-10\", 1 + 23/28, \"1 month and 14 + 9 = 25 days\",\n               \"2025-01-15\",\"2025-01-15\", 0,         \"0 months\",\n               \"2025-01-15\",\"2025-01-16\", 1/31,       \"0 months an 1 day of January\"\n               )\ndt\n\n        start        end   expected                           descr\n       &lt;char&gt;     &lt;char&gt;      &lt;num&gt;                          &lt;char&gt;\n1: 2025-01-01 2025-02-01 1.00000000                         1 month\n2: 2024-11-01 2025-02-01 3.00000000                        3 months\n3: 2025-01-01 2025-02-10 1.32142857  1 month and 9 days of February\n4: 2025-01-15 2025-02-01 0.54838710                         17 days\n5: 2025-02-01 2025-03-10 1.29032258      1 month an 9 days of March\n6: 2025-01-15 2025-03-01 1.50000000 1 month and 14 days of February\n7: 2025-01-15 2025-03-10 1.82142857    1 month and 14 + 9 = 25 days\n8: 2025-01-15 2025-01-15 0.00000000                        0 months\n9: 2025-01-15 2025-01-16 0.03225806    0 months an 1 day of January\n\n\n\n\n\n\n\n\nNote\n\n\n\nTo construct the data.table we used the rowiseDT-function of data.table which was inspired by the tribble-function of the tibble-package.\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution\nTo calculate the months we can use the following functions from the lubridate-package\n\ninterval to define a date-interval and\ntime_length to calculate the monts.\n\nLet’s see how this works. First we build the intervals\n\ndt[,interval := interval(start, end)]\ndt\n\n        start        end   expected                           descr\n       &lt;char&gt;     &lt;char&gt;      &lt;num&gt;                          &lt;char&gt;\n1: 2025-01-01 2025-02-01 1.00000000                         1 month\n2: 2024-11-01 2025-02-01 3.00000000                        3 months\n3: 2025-01-01 2025-02-10 1.32142857  1 month and 9 days of February\n4: 2025-01-15 2025-02-01 0.54838710                         17 days\n5: 2025-02-01 2025-03-10 1.29032258      1 month an 9 days of March\n6: 2025-01-15 2025-03-01 1.50000000 1 month and 14 days of February\n7: 2025-01-15 2025-03-10 1.82142857    1 month and 14 + 9 = 25 days\n8: 2025-01-15 2025-01-15 0.00000000                        0 months\n9: 2025-01-15 2025-01-16 0.03225806    0 months an 1 day of January\n                         interval\n                       &lt;Interval&gt;\n1: 2025-01-01 UTC--2025-02-01 UTC\n2: 2024-11-01 UTC--2025-02-01 UTC\n3: 2025-01-01 UTC--2025-02-10 UTC\n4: 2025-01-15 UTC--2025-02-01 UTC\n5: 2025-02-01 UTC--2025-03-10 UTC\n6: 2025-01-15 UTC--2025-03-01 UTC\n7: 2025-01-15 UTC--2025-03-10 UTC\n8: 2025-01-15 UTC--2025-01-15 UTC\n9: 2025-01-15 UTC--2025-01-16 UTC\n\n\n\n\n\n\n\n\nNote\n\n\n\nAs you can see, we didn’t even have to convert the character-dates into actual dates. The interval-function did all this for us.\n\n\nThen we calculate the months\n\ndt[,months := time_length(interval,\n                          unit = \"month\")]\ndt\n\n        start        end   expected                           descr\n       &lt;char&gt;     &lt;char&gt;      &lt;num&gt;                          &lt;char&gt;\n1: 2025-01-01 2025-02-01 1.00000000                         1 month\n2: 2024-11-01 2025-02-01 3.00000000                        3 months\n3: 2025-01-01 2025-02-10 1.32142857  1 month and 9 days of February\n4: 2025-01-15 2025-02-01 0.54838710                         17 days\n5: 2025-02-01 2025-03-10 1.29032258      1 month an 9 days of March\n6: 2025-01-15 2025-03-01 1.50000000 1 month and 14 days of February\n7: 2025-01-15 2025-03-10 1.82142857    1 month and 14 + 9 = 25 days\n8: 2025-01-15 2025-01-15 0.00000000                        0 months\n9: 2025-01-15 2025-01-16 0.03225806    0 months an 1 day of January\n                         interval     months\n                       &lt;Interval&gt;      &lt;num&gt;\n1: 2025-01-01 UTC--2025-02-01 UTC 1.00000000\n2: 2024-11-01 UTC--2025-02-01 UTC 3.00000000\n3: 2025-01-01 UTC--2025-02-10 UTC 1.32142857\n4: 2025-01-15 UTC--2025-02-01 UTC 0.54838710\n5: 2025-02-01 UTC--2025-03-10 UTC 1.29032258\n6: 2025-01-15 UTC--2025-03-01 UTC 1.50000000\n7: 2025-01-15 UTC--2025-03-10 UTC 1.82142857\n8: 2025-01-15 UTC--2025-01-15 UTC 0.00000000\n9: 2025-01-15 UTC--2025-01-16 UTC 0.03225806\n\n\nAs you can see the calculated months for the interval 2025-01-15 to 2025-03-10 (row number 7) are kind of strange in the sense, that the function calculates\n\none month from 2025-01-15 to 2025-02-15\n23 days between 2025-02-15 and 2025-03-10 (which is the correct number of days, by the way); these 23 days will be divided by 28 as the 15th is in the month of February. That will give you 0.8214286\n\nThis may not be what you like.\nIf you expected (as I did), that the interval 2025-01-15 to 2025-03-10 will give you\n\n17/31 for the 17 days of January\n1 for the month of February\n9/31 for the 9 days of March\n\ngiving 1.8387097 you will have to make sure, that an interval, that doesn’t start at the first of a month, will be split into two rows\n\nso that the end of the first row will be the first of the month following the start (see row 4) and\nthe second row will start with the first of the month following the original start-date (see row 5).\n\nIn sum these two rows will give you the expected result.\n\n\n\n\nReuseCC BY-SA 4.0"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "r-solutions",
    "section": "",
    "text": "alternatives for read.fwf\n\n\n\nnews\n\ncode\n\ndata.table\n\nLaF\n\nreadr\n\nfread\n\nlaf_open_fwf\n\nread_fwf\n\nread.fwf\n\n\n\n\n\n\n\n\n\nAug 31, 2025\n\n\nThomas Brand\n\n\n\n\n\n\n\n\n\n\n\n\nusing-fread-for-reading-csv\n\n\n\nnews\n\ncode\n\ndata.table\n\nfread\n\n\n\n\n\n\n\n\n\nJul 26, 2025\n\n\nThomas Brand\n\n\n\n\n\n\n\n\n\n\n\n\nusing foverlaps for time-slices\n\n\n\nnews\n\ncode\n\ndata.table\n\n\n\n\n\n\n\n\n\nJul 2, 2025\n\n\nThomas Brand\n\n\n\n\n\n\n\n\n\n\n\n\nCalculating months with fractions\n\n\n\nnews\n\ncode\n\nlubridate\n\ndata.table\n\nrowiseDT\n\ninterval\n\ntime_length\n\n\n\n\n\n\n\n\n\nJun 9, 2025\n\n\nThomas Brand\n\n\n\n\n\n\n\n\n\n\n\n\nUsing rmarkdown with makepipe\n\n\n\nnews\n\ncode\n\nmakepipe\n\nrmarkdown\n\nparsermd\n\n\n\n\n\n\n\n\n\nMay 22, 2025\n\n\nThomas Brand\n\n\n\n\n\nNo matching items\nReuseCC BY-SA 4.0"
  },
  {
    "objectID": "posts/using-fread-for-reading-fwf/index.html",
    "href": "posts/using-fread-for-reading-fwf/index.html",
    "title": "using fread for reading fw-files",
    "section": "",
    "text": "In this post I will show you some alternatives for the read.fwf-function for reading fixed width files, that are considerably faster than read.fwf. The solutions we will look at are:\n\nfread with preprocessing\nfread in combination with LaF::laf_open_fwf and tidyr::unite\nread_fwf from readr\n\nEach of these alternatives will give you enormous speed advantages over read.fwf."
  },
  {
    "objectID": "posts/using-fread-for-reading-fwf/index.html#timing-read.fwf",
    "href": "posts/using-fread-for-reading-fwf/index.html#timing-read.fwf",
    "title": "using fread for reading fw-files",
    "section": "Timing read.fwf",
    "text": "Timing read.fwf\nThe thing is, that read.fwf is quite slow and in no way compareable to the speed of fread.\nLet’s look at a reproducible example.\n\nlibrary(data.table)\nlibrary(nycflights23)\nlibrary(stringr)\n\n# the flights-table of nycflights23\nfl = as.data.table(flights)\n\n# make all columns character with width of 6\nfl1 = lapply(fl,str_pad, width = 6L)\nsetDT(fl1)\nfor (i in names(fl1)) {\n  fl1[is.na(col), col := \"      \",\n      env = list(col = i)]\n}\n\n# write a fixed width-file\nwrite.table(fl1,\n            file = \"~/flights.fwf\",\n            sep = \"\",\n            row.names = FALSE,\n            col.names = FALSE,\n            quote = FALSE)\n\n# write a csv-file\nfwrite(fl1,\n       file = \"~/flights.csv\",\n       quote = FALSE,\n       col.names = FALSE)\n\ntime_fwf = system.time({rfl_fwf = read.fwf(\"~/flights.fwf\",\n                                           width = c(rep(6L, times = 18),19L))})\n\ntime_csv = system.time({rfl_csv = fread(\"~/flights.csv\",\n                                        header = FALSE)})\n\nThe execution times are quite amazing\n\nf = round(time_fwf[\"elapsed\"] / time_csv[\"elapsed\"],0)\ntime_fwf\n\n   user  system elapsed \n  7.314  21.996  29.477 \n\ntime_csv\n\n   user  system elapsed \n  0.175   0.014   0.293 \n\n\nwhich means, that read.fwf was slower by a factor of 101. So it really pays to find a solution for this.\nBy the way: fread was even better at recognizing the type of datetime-variables\n\nhead(rfl_fwf, n = 1L)\n\n    V1 V2 V3 V4   V5  V6  V7 V8  V9    V10 V11    V12    V13    V14 V15  V16\n1 2023  1  1  1 2038 203 328  3 205     UA 628 N25201    EWR    SMF 367 2500\n  V17 V18                 V19\n1  20  38 2023-01-01 20:00:00\n\n\n\nhead(rfl_csv, n= 1L)\n\n      V1    V2    V3    V4    V5    V6    V7    V8    V9    V10   V11    V12\n   &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;char&gt; &lt;int&gt; &lt;char&gt;\n1:  2023     1     1     1  2038   203   328     3   205     UA   628 N25201\n      V13    V14   V15   V16   V17   V18                 V19\n   &lt;char&gt; &lt;char&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt;              &lt;POSc&gt;\n1:    EWR    SMF   367  2500    20    38 2023-01-01 20:00:00"
  },
  {
    "objectID": "posts/using-fread-for-reading-fwf/index.html#fread-with-preprocessing",
    "href": "posts/using-fread-for-reading-fwf/index.html#fread-with-preprocessing",
    "title": "using fread for reading fw-files",
    "section": "fread with preprocessing",
    "text": "fread with preprocessing\nThe fread-function of the {data.table} package has the ability to do some preprocessing via the cmd-option.\n\n\n\n\n\n\nNote\n\n\n\nFor a detailed explanation of what you can do with the data.table-package please see\nBarrett T, Dowle M, Srinivasan A, Gorecki J, Chirico M, Hocking T, Schwendinger B, Krylov I (2025). data.table: Extension of ‘data.frame’. R package version 1.17.99, https://r-datatable.com.\n\n\nWe can thus make use of the cut-command of our Operating System. The detailed options for this command may depend on your operating system. We use the MacOS-Version here.\nLet’s construct such a command\n\n# where to find the file\nfpath = \"~/flights.fwf\"\n\n# the width of the fields\nwidth = c(rep(6L, times = 18),19L)\n\n# calculating starting and ending positions\nstarting_pos = cumsum(c(1,width))\n\ncom = paste0(\n  \"awk '{ print \",\n  paste(\n    paste0(\"substr($0,\",starting_pos[1:length(width)],\",\",width,\")\"),\n    collapse = \"\\\",\\\"\"\n  ),\n  \" }' \",\n  fpath\n)\n\ncom\n\n[1] \"awk '{ print substr($0,1,6)\\\",\\\"substr($0,7,6)\\\",\\\"substr($0,13,6)\\\",\\\"substr($0,19,6)\\\",\\\"substr($0,25,6)\\\",\\\"substr($0,31,6)\\\",\\\"substr($0,37,6)\\\",\\\"substr($0,43,6)\\\",\\\"substr($0,49,6)\\\",\\\"substr($0,55,6)\\\",\\\"substr($0,61,6)\\\",\\\"substr($0,67,6)\\\",\\\"substr($0,73,6)\\\",\\\"substr($0,79,6)\\\",\\\"substr($0,85,6)\\\",\\\"substr($0,91,6)\\\",\\\"substr($0,97,6)\\\",\\\"substr($0,103,6)\\\",\\\"substr($0,109,19) }' ~/flights.fwf\"\n\n\nWith this command we will now call fread\n\nrfl_fread_fwf = fread(cmd = com,\n                      sep = \",\")"
  },
  {
    "objectID": "posts/using-fread-for-reading-fwf/index.html#fread-in-combination-with-laf",
    "href": "posts/using-fread-for-reading-fwf/index.html#fread-in-combination-with-laf",
    "title": "using fread for reading fw-files",
    "section": "fread in combination with laf",
    "text": "fread in combination with laf\nAnother way is to use the laf_open_fwf-function of the LaF-package to read the file.\n\nlibrary(LaF)\n\n# establish a file-connection\nfwfcon = laf_open_fwf(filename = fpath,\n                      column_types = rep(\"character\",times = 19),\n                      column_widths = width)\n\n# extract the data\ndf = fwfcon[1:nrow(fwfcon)]\n\n# close file-connection\nclose(fwfcon)\n\nWith this you already have a data.frame with all the columns as characters.\n\nhead(df)\n\n    V1 V2 V3  V4   V5  V6  V7   V8  V9 V10  V11    V12 V13 V14 V15  V16 V17 V18\n1 2023  1  1   1 2038 203 328    3 205  UA  628 N25201 EWR SMF 367 2500  20  38\n2 2023  1  1  18 2300  78 228  135  53  DL  393 N830DN JFK ATL 108  760  23   0\n3 2023  1  1  31 2344  47 500  426  34  B6  371 N807JB JFK BQN 190 1576  23  44\n4 2023  1  1  33 2140 173 238 2352 166  B6 1053 N265JB JFK CHS 108  636  21  40\n5 2023  1  1  36 2048 228 223 2252 211  UA  219 N17730 EWR DTW  80  488  20  48\n6 2023  1  1 503  500   3 808  815  -7  AA  499 N925AN EWR MIA 154 1085   5   0\n                  V19\n1 2023-01-01 20:00:00\n2 2023-01-01 23:00:00\n3 2023-01-01 23:00:00\n4 2023-01-01 21:00:00\n5 2023-01-01 20:00:00\n6 2023-01-01 05:00:00\n\n\nIn the next step you can either process every column separately, or you can convert this columns in one with a comma as a separator (we use the unite-function of the tidyr-package) and feed this into fread via the text-attribute\n\nlibrary(tidyr)\nrfl_fread_laf_fwf = fread(text = unite(df, col = \"v101\", sep = \",\")$v101,\n                          sep = \",\")\n\nThis gives you the following results\n\nhead(rfl_fread_laf_fwf)\n\n      V1    V2    V3    V4    V5    V6    V7    V8    V9    V10   V11    V12\n   &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;char&gt; &lt;int&gt; &lt;char&gt;\n1:  2023     1     1     1  2038   203   328     3   205     UA   628 N25201\n2:  2023     1     1    18  2300    78   228   135    53     DL   393 N830DN\n3:  2023     1     1    31  2344    47   500   426    34     B6   371 N807JB\n4:  2023     1     1    33  2140   173   238  2352   166     B6  1053 N265JB\n5:  2023     1     1    36  2048   228   223  2252   211     UA   219 N17730\n6:  2023     1     1   503   500     3   808   815    -7     AA   499 N925AN\n      V13    V14   V15   V16   V17   V18                 V19\n   &lt;char&gt; &lt;char&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt;              &lt;POSc&gt;\n1:    EWR    SMF   367  2500    20    38 2023-01-01 20:00:00\n2:    JFK    ATL   108   760    23     0 2023-01-01 23:00:00\n3:    JFK    BQN   190  1576    23    44 2023-01-01 23:00:00\n4:    JFK    CHS   108   636    21    40 2023-01-01 21:00:00\n5:    EWR    DTW    80   488    20    48 2023-01-01 20:00:00\n6:    EWR    MIA   154  1085     5     0 2023-01-01 05:00:00"
  },
  {
    "objectID": "posts/using-fread-for-reading-fwf/index.html#read_fwf",
    "href": "posts/using-fread-for-reading-fwf/index.html#read_fwf",
    "title": "using fread for reading fw-files",
    "section": "read_fwf",
    "text": "read_fwf\nYou can also use the read_fwf-function of the readr-package.\n\nlibrary(readr)\n\n\nAttaching package: 'readr'\n\n\nThe following object is masked from 'package:LaF':\n\n    read_lines\n\nrfl_readr_fwf = read_fwf(file = \"~/flights.fwf\",\n                         col_positions = fwf_widths(width))\n\nRows: 435352 Columns: 19\n\n\n── Column specification ────────────────────────────────────────────────────────\n\nchr   (4): X10, X12, X13, X14\ndbl  (14): X1, X2, X3, X4, X5, X6, X7, X8, X9, X11, X15, X16, X17, X18\ndttm  (1): X19\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nThis gives you the following results\n\nhead(rfl_readr_fwf)\n\n# A tibble: 6 × 19\n     X1    X2    X3    X4    X5    X6    X7    X8    X9 X10     X11 X12    X13  \n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;\n1  2023     1     1     1  2038   203   328     3   205 UA      628 N25201 EWR  \n2  2023     1     1    18  2300    78   228   135    53 DL      393 N830DN JFK  \n3  2023     1     1    31  2344    47   500   426    34 B6      371 N807JB JFK  \n4  2023     1     1    33  2140   173   238  2352   166 B6     1053 N265JB JFK  \n5  2023     1     1    36  2048   228   223  2252   211 UA      219 N17730 EWR  \n6  2023     1     1   503   500     3   808   815    -7 AA      499 N925AN EWR  \n# ℹ 6 more variables: X14 &lt;chr&gt;, X15 &lt;dbl&gt;, X16 &lt;dbl&gt;, X17 &lt;dbl&gt;, X18 &lt;dbl&gt;,\n#   X19 &lt;dttm&gt;\n\n\n\n\n\n\n\n\nNote\n\n\n\nAs you can see, by guessing the column type the read_fwf-function prefers numeric/double over integer. But there are also ways to specify data types for the columns to read in."
  },
  {
    "objectID": "posts/alternatives-for-read.fwf/index.html",
    "href": "posts/alternatives-for-read.fwf/index.html",
    "title": "alternatives for read.fwf",
    "section": "",
    "text": "In this post I will show you some alternatives for the read.fwf-function for reading fixed width files, that are considerably faster than read.fwf. The solutions we will look at are:\n\nfread with preprocessing\nfread in combination with LaF::laf_open_fwf and tidyr::unite\nread_fwf from readr\n\nEach of these alternatives will give you enormous speed advantages over read.fwf."
  },
  {
    "objectID": "posts/alternatives-for-read.fwf/index.html#timing-read.fwf",
    "href": "posts/alternatives-for-read.fwf/index.html#timing-read.fwf",
    "title": "alternatives for read.fwf",
    "section": "Timing read.fwf",
    "text": "Timing read.fwf\nThe thing is, that read.fwf is quite slow and in no way compareable to the speed of fread.\nLet’s look at a reproducible example.\n\nlibrary(data.table)\nlibrary(nycflights23)\nlibrary(stringr)\n\n# the flights-table of nycflights23\nfl = as.data.table(flights)\n\n# make all columns character with width of 6\nfl1 = lapply(fl,str_pad, width = 6L)\nsetDT(fl1)\nfor (i in names(fl1)) {\n  fl1[is.na(col), col := \"      \",\n      env = list(col = i)]\n}\n\n# write a fixed width-file\nwrite.table(fl1,\n            file = \"~/flights.fwf\",\n            sep = \"\",\n            row.names = FALSE,\n            col.names = FALSE,\n            quote = FALSE)\n\n# write a csv-file\nfwrite(fl1,\n       file = \"~/flights.csv\",\n       quote = FALSE,\n       col.names = FALSE)\n\ntime_fwf = system.time({rfl_fwf = read.fwf(\"~/flights.fwf\",\n                                           width = c(rep(6L, times = 18),19L))})\n\ntime_csv = system.time({rfl_csv = fread(\"~/flights.csv\",\n                                        header = FALSE)})\n\nThe execution times are quite amazing\n\nf = round(time_fwf[\"elapsed\"] / time_csv[\"elapsed\"],0)\ntime_fwf\n\n   user  system elapsed \n 16.339  42.219  58.915 \n\ntime_csv\n\n   user  system elapsed \n  0.230   0.016   0.248 \n\n\nwhich means, that read.fwf was slower by a factor of 238. So it really pays to find a solution for this.\nBy the way: fread was even better at recognizing the type of datetime-variables\n\nhead(rfl_fwf, n = 1L)\n\n    V1 V2 V3 V4   V5  V6  V7 V8  V9    V10 V11    V12    V13    V14 V15  V16\n1 2023  1  1  1 2038 203 328  3 205     UA 628 N25201    EWR    SMF 367 2500\n  V17 V18                 V19\n1  20  38 2023-01-01 20:00:00\n\n\n\nclass(rfl_fwf$V19)\n\n[1] \"character\"\n\n\n\nhead(rfl_csv, n= 1L)\n\n      V1    V2    V3    V4    V5    V6    V7    V8    V9    V10   V11    V12\n   &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;char&gt; &lt;int&gt; &lt;char&gt;\n1:  2023     1     1     1  2038   203   328     3   205     UA   628 N25201\n      V13    V14   V15   V16   V17   V18                 V19\n   &lt;char&gt; &lt;char&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt;              &lt;POSc&gt;\n1:    EWR    SMF   367  2500    20    38 2023-01-01 20:00:00\n\n\n\nclass(rfl_csv$V19)\n\n[1] \"POSIXct\" \"POSIXt\""
  },
  {
    "objectID": "posts/alternatives-for-read.fwf/index.html#fread-with-preprocessing",
    "href": "posts/alternatives-for-read.fwf/index.html#fread-with-preprocessing",
    "title": "alternatives for read.fwf",
    "section": "fread with preprocessing",
    "text": "fread with preprocessing\nThe fread-function of the {data.table} package has the ability to do some preprocessing via the cmd-option.\n\n\n\n\n\n\nNote\n\n\n\nFor a detailed explanation of what you can do with the data.table-package please see\nBarrett T, Dowle M, Srinivasan A, Gorecki J, Chirico M, Hocking T, Schwendinger B, Krylov I (2025). data.table: Extension of ‘data.frame’. R package version 1.17.99, https://r-datatable.com.\n\n\nWe can thus make use of the awk-command of our Operating System. The detailed options for this command may depend on your operating system. We use the MacOS-Version here.\nLet’s construct such a command\n\n# where to find the file\nfpath = \"~/flights.fwf\"\n\n# the width of the fields\nwidth = c(rep(6L, times = 18),19L)\n\n# calculating starting and ending positions\nstarting_pos = cumsum(c(1,width))\n\ncom = paste0(\n  \"awk '{ print \",\n  paste(\n    paste0(\"substr($0,\",starting_pos[1:length(width)],\",\",width,\")\"),\n    collapse = \"\\\",\\\"\"\n  ),\n  \" }' \",\n  fpath\n)\n\ncom\n\n[1] \"awk '{ print substr($0,1,6)\\\",\\\"substr($0,7,6)\\\",\\\"substr($0,13,6)\\\",\\\"substr($0,19,6)\\\",\\\"substr($0,25,6)\\\",\\\"substr($0,31,6)\\\",\\\"substr($0,37,6)\\\",\\\"substr($0,43,6)\\\",\\\"substr($0,49,6)\\\",\\\"substr($0,55,6)\\\",\\\"substr($0,61,6)\\\",\\\"substr($0,67,6)\\\",\\\"substr($0,73,6)\\\",\\\"substr($0,79,6)\\\",\\\"substr($0,85,6)\\\",\\\"substr($0,91,6)\\\",\\\"substr($0,97,6)\\\",\\\"substr($0,103,6)\\\",\\\"substr($0,109,19) }' ~/flights.fwf\"\n\n\nWith this command we will now call fread\n\nrfl_fread_fwf = fread(cmd = com,\n                      sep = \",\")\n\n\n\n\n\n\n\nNote\n\n\n\nWe were using the awk-command here. This is because of the MasOS I’m using. In another OS you can use the cut-command with the –output-delimiter option. So you would have something like\n\n# the width of the fields\nwidth = c(rep(6L, times = 18),19L)\n\n# calculating starting and ending positions\nstarting_pos = cumsum(c(1,width))\nending_pos = cumsum(width)\n\nlimits = paste(paste(starting_pos[1:length(width)],ending_pos,sep = \"-\"), collapse = \",\")\n\ncom2 = paste0(\"cut --output-delimiter=\\\",\\\" --characters=\",limits,\" \",fpath)\ncom2\n\n[1] \"cut --output-delimiter=\\\",\\\" --characters=1-6,7-12,13-18,19-24,25-30,31-36,37-42,43-48,49-54,55-60,61-66,67-72,73-78,79-84,85-90,91-96,97-102,103-108,109-127 ~/flights.fwf\""
  },
  {
    "objectID": "posts/alternatives-for-read.fwf/index.html#fread-in-combination-with-laf",
    "href": "posts/alternatives-for-read.fwf/index.html#fread-in-combination-with-laf",
    "title": "alternatives for read.fwf",
    "section": "fread in combination with laf",
    "text": "fread in combination with laf\nAnother way is to use the laf_open_fwf -function of the LaF-package to read the file.\n\nlibrary(LaF)\n\n# establish a file-connection\nfwfcon = laf_open_fwf(filename = fpath,\n                      column_types = rep(\"character\",times = 19),\n                      column_widths = width)\n\n# extract the data\ndf = fwfcon[1:nrow(fwfcon)]\n\n# close file-connection\nclose(fwfcon)\n\nWith this you already have a data.frame with all the columns as characters.\n\nhead(df)\n\n    V1 V2 V3  V4   V5  V6  V7   V8  V9 V10  V11    V12 V13 V14 V15  V16 V17 V18\n1 2023  1  1   1 2038 203 328    3 205  UA  628 N25201 EWR SMF 367 2500  20  38\n2 2023  1  1  18 2300  78 228  135  53  DL  393 N830DN JFK ATL 108  760  23   0\n3 2023  1  1  31 2344  47 500  426  34  B6  371 N807JB JFK BQN 190 1576  23  44\n4 2023  1  1  33 2140 173 238 2352 166  B6 1053 N265JB JFK CHS 108  636  21  40\n5 2023  1  1  36 2048 228 223 2252 211  UA  219 N17730 EWR DTW  80  488  20  48\n6 2023  1  1 503  500   3 808  815  -7  AA  499 N925AN EWR MIA 154 1085   5   0\n                  V19\n1 2023-01-01 20:00:00\n2 2023-01-01 23:00:00\n3 2023-01-01 23:00:00\n4 2023-01-01 21:00:00\n5 2023-01-01 20:00:00\n6 2023-01-01 05:00:00\n\n\nIn the next step you can either process every column separately, or you can convert this columns in one with a comma as a separator (we use the unite-function of the tidyr-package) and feed this into fread via the text-attribute (which shows the flexibility of the fread-function).\n\nlibrary(tidyr)\nrfl_fread_laf_fwf = fread(text = unite(df, col = \"v101\", sep = \",\")$v101,\n                          sep = \",\")\n\nThis gives you the following results\n\nhead(rfl_fread_laf_fwf)\n\n      V1    V2    V3    V4    V5    V6    V7    V8    V9    V10   V11    V12\n   &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;char&gt; &lt;int&gt; &lt;char&gt;\n1:  2023     1     1     1  2038   203   328     3   205     UA   628 N25201\n2:  2023     1     1    18  2300    78   228   135    53     DL   393 N830DN\n3:  2023     1     1    31  2344    47   500   426    34     B6   371 N807JB\n4:  2023     1     1    33  2140   173   238  2352   166     B6  1053 N265JB\n5:  2023     1     1    36  2048   228   223  2252   211     UA   219 N17730\n6:  2023     1     1   503   500     3   808   815    -7     AA   499 N925AN\n      V13    V14   V15   V16   V17   V18                 V19\n   &lt;char&gt; &lt;char&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt;              &lt;POSc&gt;\n1:    EWR    SMF   367  2500    20    38 2023-01-01 20:00:00\n2:    JFK    ATL   108   760    23     0 2023-01-01 23:00:00\n3:    JFK    BQN   190  1576    23    44 2023-01-01 23:00:00\n4:    JFK    CHS   108   636    21    40 2023-01-01 21:00:00\n5:    EWR    DTW    80   488    20    48 2023-01-01 20:00:00\n6:    EWR    MIA   154  1085     5     0 2023-01-01 05:00:00"
  },
  {
    "objectID": "posts/alternatives-for-read.fwf/index.html#read_fwf",
    "href": "posts/alternatives-for-read.fwf/index.html#read_fwf",
    "title": "alternatives for read.fwf",
    "section": "read_fwf",
    "text": "read_fwf\nYou can also use the read_fwf-function of the readr-package.\n\n\n\n\n\n\nNote\n\n\n\nFor a detailes explanation of what the readr-Package can do, please see\nWickham H, Hester J, Bryan J (2024). readr: Read Rectangular Text Data. R package version 2.1.5, https://github.com/tidyverse/readr, https://readr.tidyverse.org.\n\n\n\nlibrary(readr)\n\n\nAttaching package: 'readr'\n\n\nThe following object is masked from 'package:LaF':\n\n    read_lines\n\nrfl_readr_fwf = read_fwf(file = \"~/flights.fwf\",\n                         col_positions = fwf_widths(width))\n\nRows: 435352 Columns: 19\n\n\n── Column specification ────────────────────────────────────────────────────────\n\nchr   (4): X10, X12, X13, X14\ndbl  (14): X1, X2, X3, X4, X5, X6, X7, X8, X9, X11, X15, X16, X17, X18\ndttm  (1): X19\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nThis is quite an easy and straightforward way of reading fw-files and gives you the following results\n\nhead(rfl_readr_fwf)\n\n# A tibble: 6 × 19\n     X1    X2    X3    X4    X5    X6    X7    X8    X9 X10     X11 X12    X13  \n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;\n1  2023     1     1     1  2038   203   328     3   205 UA      628 N25201 EWR  \n2  2023     1     1    18  2300    78   228   135    53 DL      393 N830DN JFK  \n3  2023     1     1    31  2344    47   500   426    34 B6      371 N807JB JFK  \n4  2023     1     1    33  2140   173   238  2352   166 B6     1053 N265JB JFK  \n5  2023     1     1    36  2048   228   223  2252   211 UA      219 N17730 EWR  \n6  2023     1     1   503   500     3   808   815    -7 AA      499 N925AN EWR  \n# ℹ 6 more variables: X14 &lt;chr&gt;, X15 &lt;dbl&gt;, X16 &lt;dbl&gt;, X17 &lt;dbl&gt;, X18 &lt;dbl&gt;,\n#   X19 &lt;dttm&gt;\n\n\n\n\n\n\n\n\nNote\n\n\n\nAs you can see, by guessing the column type the read_fwf-function prefers numeric/double over integer. But there are also ways to specify data types for the columns to read in."
  },
  {
    "objectID": "posts/filter-functions-for-data-table/index.html",
    "href": "posts/filter-functions-for-data-table/index.html",
    "title": "filter functions for data.table",
    "section": "",
    "text": "Abstract\n\n\nMotivation\nThe {data.table} package provides a very sophisticated way of filtering tables. Be ist just to extract all rows that fit a certain criteria or to manipulate/update data in the table for just the selected lines.\nLet’s create some example data\n\nlibrary(data.table)\n\ndt = data.table(A = rep(LETTERS[1:3],times = 4),\n                B = rep(letters[4:9],times = 2),\n                C = seq(from = 0.02, by = 0.1, length.out = 12),\n                D = seq(from = as.Date(\"2025-10-01\"), by = \"day\", length.out = 12)\n)\ndt\n\n         A      B     C          D\n    &lt;char&gt; &lt;char&gt; &lt;num&gt;     &lt;Date&gt;\n 1:      A      d  0.02 2025-10-01\n 2:      B      e  0.12 2025-10-02\n 3:      C      f  0.22 2025-10-03\n 4:      A      g  0.32 2025-10-04\n 5:      B      h  0.42 2025-10-05\n 6:      C      i  0.52 2025-10-06\n 7:      A      d  0.62 2025-10-07\n 8:      B      e  0.72 2025-10-08\n 9:      C      f  0.82 2025-10-09\n10:      A      g  0.92 2025-10-10\n11:      B      h  1.02 2025-10-11\n12:      C      i  1.12 2025-10-12\n\n\nand filter them in the ordinary way:\n\ndt[A == \"B\"]\n\n        A      B     C          D\n   &lt;char&gt; &lt;char&gt; &lt;num&gt;     &lt;Date&gt;\n1:      B      e  0.12 2025-10-02\n2:      B      h  0.42 2025-10-05\n3:      B      e  0.72 2025-10-08\n4:      B      h  1.02 2025-10-11\n\n\nLets define a filter-expression via bquote\n\nf1 = bquote(A == \"B\") \ndt[eval(f1)]\n\n        A      B     C          D\n   &lt;char&gt; &lt;char&gt; &lt;num&gt;     &lt;Date&gt;\n1:      B      e  0.12 2025-10-02\n2:      B      h  0.42 2025-10-05\n3:      B      e  0.72 2025-10-08\n4:      B      h  1.02 2025-10-11\n\n\nYou can also combine several filters via .()`\n\nf2 = bquote(D &gt; as.Date(\"2025-10-06\"))\nf1and2 = bquote(.(f1) & .(f2))\ndt[eval(f1and2)]\n\n        A      B     C          D\n   &lt;char&gt; &lt;char&gt; &lt;num&gt;     &lt;Date&gt;\n1:      B      e  0.72 2025-10-08\n2:      B      h  1.02 2025-10-11\n\n\nAnd in the same way you can update a data.table for just the rows that corresponds to the filter\n\ndt2 = copy(dt)\ndt2[eval(f1and2), ':='(E = \"these rows were filterd\")]\ndt2\n\nIndex: &lt;A&gt;\n         A      B     C          D                       E\n    &lt;char&gt; &lt;char&gt; &lt;num&gt;     &lt;Date&gt;                  &lt;char&gt;\n 1:      A      d  0.02 2025-10-01                    &lt;NA&gt;\n 2:      B      e  0.12 2025-10-02                    &lt;NA&gt;\n 3:      C      f  0.22 2025-10-03                    &lt;NA&gt;\n 4:      A      g  0.32 2025-10-04                    &lt;NA&gt;\n 5:      B      h  0.42 2025-10-05                    &lt;NA&gt;\n 6:      C      i  0.52 2025-10-06                    &lt;NA&gt;\n 7:      A      d  0.62 2025-10-07                    &lt;NA&gt;\n 8:      B      e  0.72 2025-10-08 these rows were filterd\n 9:      C      f  0.82 2025-10-09                    &lt;NA&gt;\n10:      A      g  0.92 2025-10-10                    &lt;NA&gt;\n11:      B      h  1.02 2025-10-11 these rows were filterd\n12:      C      i  1.12 2025-10-12                    &lt;NA&gt;\n\n\n\n\n\n\n\n\nImportant\n\n\n\nThis works great, but is a lot of code to write, especially if you have work with the same filters on the same kind of data structure over and over again and probably want to combine one or several of them.\n\n\n\n\nSolution\nLets construct a set of functions the will do the filtering\n\na function that executes a filter\na function that adds a filter with &\na function that adds a filter with |\na function that negates an existing filter\n\n\n# a simple function to execute the filter\nexecFilter = function(dt, f) {\n  dt[eval(f)]\n}\n\n# add another filter by \"and\"\nandFilter = function(f, andf) {\n  bquote(.(f) & .(andf))\n}\n\n# add another filter by \"or\"\norFilter = function(f, orf) {\n bquote(.(f) | .(orf)) \n}\n\n# negate filter\nnegFilter = function(f) {\n  bquote(!.(f))\n}\n\n\n\n\n\n\n\nNote\n\n\n\nIn a real life scenario we would put in additional checks for the added filters.\n\n\nLet’s see these functions in action. We want to construct a filter, that negates our f1and2` filter or where the value in column C` is either 0.32 or 0.42:\n\nCvalues = c(0.32, 0.42)\n# create a filter and \nf1 |&gt; \n  andFilter(f2) |&gt;\n  negFilter() |&gt;\n  orFilter(bquote(C %in% .(Cvalues))) -&gt; myFilter\n\nmyFilter\n\n!(A == \"B\" & D &gt; as.Date(\"2025-10-06\")) | C %in% c(0.32, 0.42\n)\n\n\nWe can apply this filter\n\nexecFilter(dt, myFilter)\n\n         A      B     C          D\n    &lt;char&gt; &lt;char&gt; &lt;num&gt;     &lt;Date&gt;\n 1:      A      d  0.02 2025-10-01\n 2:      B      e  0.12 2025-10-02\n 3:      C      f  0.22 2025-10-03\n 4:      A      g  0.32 2025-10-04\n 5:      B      h  0.42 2025-10-05\n 6:      C      i  0.52 2025-10-06\n 7:      A      d  0.62 2025-10-07\n 8:      C      f  0.82 2025-10-09\n 9:      A      g  0.92 2025-10-10\n10:      C      i  1.12 2025-10-12\n\n\nFor convenience I would recommend to put these functions and filters in a Package. Additionally to the filters I would create special functions that execute my filters. e.g.\n\ngetf1and2 = function(dt) {\n  dt[eval(f1and2)]\n}\n\ngetMyFilter = function(dt) {\n  dt[eval(myFilter)]\n}\n\n\n\n\n\nReuseCC BY-SA 4.0"
  }
]